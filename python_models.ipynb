{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /opt/conda/anaconda/lib/python3.6/site-packages (20.0.2)\n",
      "Requirement already satisfied: xgboost in /opt/conda/anaconda/lib/python3.6/site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/anaconda/lib/python3.6/site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/anaconda/lib/python3.6/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: lightgbm in /opt/conda/anaconda/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/anaconda/lib/python3.6/site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/anaconda/lib/python3.6/site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/anaconda/lib/python3.6/site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: gcsfs in /opt/conda/anaconda/lib/python3.6/site-packages (0.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/anaconda/lib/python3.6/site-packages (from gcsfs) (2.22.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from gcsfs) (1.11.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/anaconda/lib/python3.6/site-packages (from gcsfs) (4.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/anaconda/lib/python3.6/site-packages (from gcsfs) (0.4.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from gcsfs) (0.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests->gcsfs) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests->gcsfs) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests->gcsfs) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests->gcsfs) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from google-auth>=1.2->gcsfs) (1.14.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from google-auth>=1.2->gcsfs) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/anaconda/lib/python3.6/site-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from google-auth>=1.2->gcsfs) (45.2.0.post20200210)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/anaconda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
      "Requirement already satisfied: spacy in /opt/conda/anaconda/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (4.43.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy) (45.2.0.post20200210)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/anaconda/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
      "Requirement already satisfied: keras in /opt/conda/anaconda/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/anaconda/lib/python3.6/site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: h5py in /opt/conda/anaconda/lib/python3.6/site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/anaconda/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/anaconda/lib/python3.6/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: textblob in /opt/conda/anaconda/lib/python3.6/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from textblob) (3.3)\n",
      "Requirement already satisfied: six in /opt/conda/anaconda/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /opt/conda/anaconda/lib/python3.6/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.2.0.post20200210)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/anaconda/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /opt/conda/anaconda/lib/python3.6/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/anaconda/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (45.2.0.post20200210)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/anaconda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/anaconda/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/anaconda/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install gcsfs\n",
    "!pip install spacy\n",
    "!pip install keras\n",
    "!pip install textblob\n",
    "!python3 -m spacy download en\n",
    "!python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.6.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(\"python version: \", python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/distributed/config.py:63: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config.update(yaml.load(text) or {})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 877 ms, sys: 99 ms, total: 976 ms\n",
      "Wall time: 973 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os, sys, time, json, re, string, datetime \n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from google.cloud import storage\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, Normalizer, normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import sklearn.tree as skt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.core     import XGBoostError\n",
    "import xgboost as xgb\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm.sklearn import LightGBMError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44183 entries, 0 to 44182\n",
      "Data columns (total 3 columns):\n",
      "Comment    44183 non-null object\n",
      "Outcome    44183 non-null int64\n",
      "Id         44183 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.0+ MB\n",
      "CPU times: user 449 ms, sys: 55 ms, total: 504 ms\n",
      "Wall time: 1.08 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    24992\n",
       "0    19191\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv('gs://dataproc-6ca41800-27b4-47d5-abee-55c011dfa389-asia-southeast1/data/kaggle/train.csv')\n",
    "df_train.info()\n",
    "df_train['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "class TextFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.nlp = en_core_web_sm.load()\n",
    "        self.future_words = [\"tomorrow\", \"future\", \"futures\"]\n",
    "        self.past_words = [\"yesterday\", \"past\",\"pasts\"]\n",
    "        self.first_view_words = [\"I\", \"my\", \"mine\"]\n",
    "        self.second_view_words = [\"you\", \"your\", \"yours\"]\n",
    "        self.third_view_words = [\"they\", \"their\", \"them\"]\n",
    "        self.it_view_words = [\"it\", \"its\"]\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def count_pronouns(doc):\n",
    "        segment = doc.text.lower().split()\n",
    "        counter = {\"1sg\": 0, \"1pl\": 0}\n",
    "        for pronoun in FIRST_SINGULAR:\n",
    "            counter[\"1sg\"] += segment.count(pronoun)\n",
    "        for pronoun in FIRST_PLURAL:\n",
    "            counter[\"1pl\"] += segment.count(pronoun)\n",
    "        return counter\n",
    "\n",
    "    def get_n_future_oriented_words(self, doc):\n",
    "        will_aux = [t for t in doc if t.tag_ == \"MD\" and t.lower_ in {\"will\", \"wo\", \"shall\", \"sha\"}]\n",
    "        going_to = [t for t in doc if t.dep_ == \"xcomp\" and t.head.lemma_ == \"go\"]\n",
    "        other_future_words = [t for t in doc if t.lower_ in self.future_words]\n",
    "        return len(will_aux) + len(going_to) + len(other_future_words)\n",
    "\n",
    "    def get_n_past_oriented_words(self, doc):\n",
    "        would_aux = [t for t in doc if t.tag_ == \"MD\" and t.lower_ in {\"would\", \"wouldn't\", \"should\", \"shouldn't\"}]\n",
    "        went_to = [t for t in doc if t.dep_ == \"xcomp\" and t.head.lemma_ == \"went\"]\n",
    "        other_past_words = [t for t in doc if t.lower_ in self.past_words]\n",
    "        return len(would_aux) + len(went_to) + len(other_past_words)\n",
    "    \n",
    "    def get_n_view_words(self, doc, list):\n",
    "        n_first_view_words = [t for t in doc if t.lower_ in self.first_view_words]\n",
    "        return len(n_first_view_words) \n",
    "\n",
    "    def get_n_words_before_main_verb(self,doc):\n",
    "        numbers = [0]\n",
    "        for sent in doc.sents:\n",
    "            main = [t for t in sent if t.dep_ == \"ROOT\"][0]\n",
    "            if main.pos_ == \"VERB\":\n",
    "                dist_to_init = main.i - sent[0].i\n",
    "                numbers.append(dist_to_init)\n",
    "        return np.mean(numbers)\n",
    "\n",
    "    def get_n_complex_clauses(self,doc):\n",
    "        embedded_elements_count = []\n",
    "        for sent in doc.sents:\n",
    "            n_embedded = len(\n",
    "                [t for t in sent if t.dep_ in {\"ccomp\", \"xcomp\", \"advcl\", \"dative\"}]\n",
    "            )\n",
    "            embedded_elements_count.append(n_embedded)\n",
    "        return np.mean(embedded_elements_count)\n",
    "    \n",
    "    def get_n_punctuation(self,doc):\n",
    "        word_count = len(doc)\n",
    "        unique_word_count = len(set(doc))\n",
    "        char_count = 0 \n",
    "        dict_punct_count = {}\n",
    "        for c in doc:\n",
    "            if str(c) in string.punctuation:\n",
    "                dict_punct_count[str(c)] = dict_punct_count.get(str(c), 0) + 1\n",
    "            else: \n",
    "                char_count += 1\n",
    "        \n",
    "        punctuation_count = sum(dict_punct_count.values())        \n",
    "        feature_dict = { \n",
    "                \"n_word_count\": word_count, \n",
    "                \"n_char_count\": char_count, \n",
    "                \"n_char_count_percentage\": char_count / (word_count + 1e-10),  \n",
    "                \"n_unique_word_count\": unique_word_count, \n",
    "                \"n_unique_word_count_percentage\": unique_word_count / (word_count + 1e-10),\n",
    "                \"n_punctuation_count\": punctuation_count, \n",
    "                \"n_punctuation_count_percentage\": punctuation_count / (word_count + 1e-10)}\n",
    "       \n",
    "        puntuation_list = [\"!\", \"?\", \"=\", \"{\", \"<\", \">\", \"(\", \"+\", \"-\", \"*\", \"/\", \"[\",\"#\"]\n",
    "        puntuation_dict={}        \n",
    "        feature_dicts = []\n",
    "        i = 0\n",
    "        for key in dict_punct_count: \n",
    "            value = 0.0\n",
    "            dict_name = \"n_punctuation_count_\" + str(i)\n",
    "            dict_name_precentage = dict_name + \"_p\"\n",
    "            for p in puntuation_list:\n",
    "                if key == p:\n",
    "                    value = dict_punct_count.get(key, 0)\n",
    "                    \n",
    "            p_dict = {dict_name: value, dict_name_precentage: value / (word_count + 1e-10)}\n",
    "            puntuation_dict.update(p_dict)\n",
    "            i = i + 1\n",
    "        \n",
    "        return puntuation_dict  \n",
    "    \n",
    "    \n",
    "    def get_n_pos(self,doc):\n",
    "        word_count = len(doc)\n",
    "        pos_family = {'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "                      'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "                      'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "                      'adj' :  ['JJ','JJR','JJS'],\n",
    "                      'adv' : ['RB','RBR','RBS','WRB']}\n",
    "        dict = {'noun_count' : 0, 'noun_p' : 0,\n",
    "                'pronn_count' : 0, 'pronn_p' : 0,\n",
    "                'verbn_count' : 0, 'verbn_p' : 0,\n",
    "                'adjn_count' :  0, 'adjn_p' :  0,\n",
    "                'advn_count' : 0, 'advn_p' : 0}\n",
    "        for key in pos_family: \n",
    "            cnt = 0\n",
    "            for flag in pos_family.get(key,0):\n",
    "                try:\n",
    "                    tags = textblob.TextBlob(doc).tags\n",
    "                    for tup in tags:\n",
    "                        ppo = list(tup)[1]\n",
    "                        if ppo in pos_family[flag]:\n",
    "                            cnt += 1\n",
    "                except:\n",
    "                    pass   \n",
    "            dict.update({key + '_count': cnt,key + '_p':cnt/word_count}) \n",
    "        return dict     \n",
    "    \n",
    "    def transform(self, data):\n",
    "        feature_dicts = []\n",
    "        docs = self.nlp.pipe(data)\n",
    "        for doc in docs:\n",
    "            doc_len = len(doc)\n",
    "            n_past_oriented_words = self.get_n_past_oriented_words(doc)\n",
    "            n_future_oriented_words = self.get_n_future_oriented_words(doc)\n",
    "            n_words_before_main_verb = self.get_n_words_before_main_verb(doc)\n",
    "            n_complex_clauses = self.get_n_complex_clauses(doc)\n",
    "            n_first_view_words = self.get_n_view_words(doc, self.first_view_words)\n",
    "            n_second_view_words = self.get_n_view_words(doc, self.second_view_words)\n",
    "            n_third_view_words = self.get_n_view_words(doc, self.third_view_words)\n",
    "            n_it_view_words = self.get_n_view_words(doc, self.it_view_words)            \n",
    "            feature_dict = {\n",
    "                \"n_past_oriented_words\": n_past_oriented_words,\n",
    "                \"p_past_oriented_words\": n_past_oriented_words / doc_len,\n",
    "                \"n_future_oriented_words\": n_future_oriented_words,\n",
    "                \"p_future_oriented_words\": n_future_oriented_words / doc_len,\n",
    "                \"n_complex_clauses\": n_complex_clauses,\n",
    "                \"p_complex_clauses\": n_complex_clauses / doc_len,\n",
    "                \"n_words_before_main_verb\": n_words_before_main_verb,\n",
    "                \"p_words_before_main_verb\": n_words_before_main_verb / doc_len,\n",
    "                \"n_complex_clauses\": n_complex_clauses,\n",
    "                \"p_complex_clauses\": n_complex_clauses / doc_len,\n",
    "                \"n_first_view_words\": n_first_view_words,\n",
    "                \"p_first_view_words\": n_first_view_words / doc_len,\n",
    "                \"n_second_view_words\": n_second_view_words,\n",
    "                \"p_second_view_words\": n_second_view_words / doc_len,\n",
    "                \"n_third_view_words\": n_third_view_words,\n",
    "                \"p_third_view_words\": n_third_view_words / doc_len,\n",
    "                \"n_it_view_words\": n_it_view_words,\n",
    "                \"p_it_view_words\": n_it_view_words / doc_len   \n",
    "            }\n",
    "            puntuation_dict = self.get_n_punctuation(doc)\n",
    "            feature_dict.update(puntuation_dict)            \n",
    "            pos_dict = self.get_n_pos(doc)\n",
    "            feature_dict.update(pos_dict)\n",
    "            \n",
    "            feature_dicts.append(feature_dict)\n",
    "        return feature_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.63 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def build_pipeline():\n",
    "    base_pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"tfidf\", TfidfVectorizer())\n",
    "        ]\n",
    "    )   \n",
    "    word_pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"word_stats\", TextFeatureTransformer()),\n",
    "            (\"word_dict_vect\", DictVectorizer())\n",
    "        ]\n",
    "    )\n",
    "    combined_features = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            (\"base\", base_pipeline),\n",
    "            (\"word\", word_pipeline)\n",
    "        ]\n",
    "    )  \n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(): \n",
    "    clf_logis = LogisticRegression(random_state=100, solver='lbfgs', multi_class='multinomial',max_iter=500, n_jobs=-1)\n",
    "    \n",
    "    clf_dt = DecisionTreeClassifier(max_depth=5, random_state=100)\n",
    " \n",
    "    clf_gbt= GradientBoostingClassifier(n_estimators=500, learning_rate=0.1, random_state=100)\n",
    "   \n",
    "    clf_gnb = GaussianNB(priors = None)\n",
    "          \n",
    "    clf_rfc = RandomForestClassifier(n_estimators = 50, max_depth = 5)\n",
    "    \n",
    "    clf_knn = KNeighborsClassifier(n_neighbors = 5, algorithm = 'auto', leaf_size = 30)\n",
    "   \n",
    "    clf_lgbm= LGBMClassifier(n_jobs=-1, random_state=100, \n",
    "                             subsample=0.3, num_trees=200, \n",
    "                             n_estimators=100, min_child_weight=0.01, \n",
    "                             max_depth=1, learning_rate=0.1, \n",
    "                             gamma=1, colsample_bytree=0.6)\n",
    "    \n",
    "    clf_xgb = XGBClassifier(objective='binary:logistic', random_state=100,\n",
    "                            subsample=1, num_trees=200, \n",
    "                            n_estimators=500, min_child_weight=0.01, \n",
    "                            max_depth=1, learning_rate=0.1, \n",
    "                            gamma=0.01, colsample_bytree=0.3)\n",
    "    \n",
    "    param_tune = {'max_depth': range(1, 3, 5),\n",
    "                  'min_child_weight': [0.01, 0.1, 1],\n",
    "                  'gamma':[1, 0.1, 0.01],\n",
    "                  'subsample':[0.3, 0.6, 1],\n",
    "                  'colsample_bytree':[0.3, 0.6, 1],\n",
    "                  'num_trees':[100, 200, 300],\n",
    "                  'learning_rate':[0.01, 0.1],\n",
    "                  'n_estimators': [100,300,500]}\n",
    "    \n",
    "    clf_logis_param_tune = {'penalty':['l2'], \n",
    "                            'C':[0.01,0.05,0.1,0.5,1,5,10,50,100], \n",
    "                            'solver':['lbfgs'],\n",
    "                            'multi_class':['ovr','multinomial']}\n",
    "   \n",
    "    ##[model_name, model, parameter_gride, run_flag, tuning_flag, probability_col]\n",
    "    models = [[\"LogisticRegression\", clf_logis, clf_logis_param_tune, True, False],\n",
    "              [\"DecisionTreeClassifier\",clf_dt, param_tune, True, False],              \n",
    "              [\"GaussianNB\",clf_gnb, param_tune, False, False],\n",
    "              [\"RandomForestClassifier\", clf_rfc, param_tune, True, False],\n",
    "              [\"KNeighborsClassifier\" , clf_knn, param_tune, True, False],\n",
    "              [\"LGBMClassifier\" , clf_lgbm, param_tune, True, False],\n",
    "              [\"XGBClassifier\" , clf_xgb, param_tune, True, False]]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(models, X_train, y_train, X_test, y_test): \n",
    "    df_outcome = pd.DataFrame(columns=['model_name', 'model_object', 'cv_train', 'train_accuray_score', 'test_accuray_score'])      \n",
    "    kfold= StratifiedKFold(n_splits=5, random_state=100) \n",
    "    for item in models:        \n",
    "        name = item[0]\n",
    "        model = item[1]\n",
    "        param_tune = item[2]\n",
    "        run_flag = item[3]\n",
    "        tuning_flag = item[4]       \n",
    "        if run_flag:                \n",
    "            print(\"**********Run Model {0}**********\".format(name))    \n",
    "            t = time.time()\n",
    "            if tuning_flag: \n",
    "                model = RandomizedSearchCV(estimator = model, param_distributions = param_tune,\n",
    "                                           scoring = \"accuracy\", n_jobs = -1, cv = 5, verbose=0)\n",
    "                model.fit(X_train, y_train) \n",
    "                print(\"{0} Best Parameters: {1}\".format(name, model.best_params_))\n",
    "            else:\n",
    "                model.fit(X_train, y_train)            \n",
    "            cv_results = cross_val_score(model, X_train, y_train, cv=kfold).mean()    \n",
    "            train_score = metrics.accuracy_score(model.predict(X_train), y_train)\n",
    "            test_score = metrics.accuracy_score(model.predict(X_test), y_test)\n",
    "            vals = [[name, model, cv_results, train_score, test_score]]\n",
    "            df2 = pd.DataFrame(vals, columns=df_outcome.columns)\n",
    "            df_outcome = df_outcome.append(df2)  \n",
    "            print(\"{0} -  train_score: {1}, test_score:{2}\".format(name, train_score, test_score))\n",
    "            print(\"time taken for {0}: {1}\".format(name, str(datetime.timedelta(seconds=time.time() - t))))\n",
    "    \n",
    "    return df_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for fit.602.51136302948\n",
      "time taken for X_train_transformated.587.1272983551025\n",
      "time taken for X_train_transformated.148.87236094474792\n",
      "CPU times: user 19min 20s, sys: 2min 58s, total: 22min 18s\n",
      "Wall time: 22min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ms = time.time()\n",
    "small_smaple_flag= False\n",
    "sample_df_train = df_train.sample(frac=0.01, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df_train.Comment, sample_df_train.Outcome, test_size=0.2)\n",
    "if small_smaple_flag == False:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_train.Comment, df_train.Outcome, test_size=0.2)\n",
    "\n",
    "pipeline = build_pipeline().fit(X_train)\n",
    "print(\"time taken for fit.{0}\".format(time.time() - ms))\n",
    "ms = time.time()\n",
    "X_train_transformated = pipeline.transform(X_train)\n",
    "print(\"time taken for X_train_transformated.{0}\".format(time.time() - ms))\n",
    "ms = time.time()\n",
    "X_test_transformated = pipeline.transform(X_test)\n",
    "print(\"time taken for X_train_transformated.{0}\".format(time.time() - ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Run Model LogisticRegression**********\n",
      "LogisticRegression -  train_score: 0.8071634696995417, test_score:0.7054430236505601\n",
      "time taken for LogisticRegression: 0:06:21.830647\n",
      "**********Run Model DecisionTreeClassifier**********\n",
      "DecisionTreeClassifier -  train_score: 0.6258699711424206, test_score:0.6040511485798348\n",
      "time taken for DecisionTreeClassifier: 0:00:22.427599\n",
      "**********Run Model RandomForestClassifier**********\n",
      "RandomForestClassifier -  train_score: 0.5671928931137894, test_score:0.559465882086681\n",
      "time taken for RandomForestClassifier: 0:00:11.974119\n",
      "**********Run Model KNeighborsClassifier**********\n",
      "KNeighborsClassifier -  train_score: 0.714338256096871, test_score:0.5551657802421637\n",
      "time taken for KNeighborsClassifier: 0:08:41.905723\n",
      "**********Run Model LGBMClassifier**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier -  train_score: 0.6638657839642392, test_score:0.6430915469050583\n",
      "time taken for LGBMClassifier: 0:00:09.138587\n",
      "**********Run Model XGBClassifier**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier -  train_score: 0.697844169071465, test_score:0.6774923616611972\n",
      "time taken for XGBClassifier: 0:01:30.874204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_object</th>\n",
       "      <th>cv_train</th>\n",
       "      <th>train_accuray_score</th>\n",
       "      <th>test_accuray_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.704804</td>\n",
       "      <td>0.807163</td>\n",
       "      <td>0.705443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster=None, co...</td>\n",
       "      <td>0.682794</td>\n",
       "      <td>0.697844</td>\n",
       "      <td>0.677492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>LGBMClassifier(boosting_type='gbdt', class_wei...</td>\n",
       "      <td>0.658321</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>0.643092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.612262</td>\n",
       "      <td>0.625870</td>\n",
       "      <td>0.604051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.567193</td>\n",
       "      <td>0.567193</td>\n",
       "      <td>0.559466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.556583</td>\n",
       "      <td>0.714338</td>\n",
       "      <td>0.555166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name                                       model_object  \\\n",
       "0      LogisticRegression  LogisticRegression(C=1.0, class_weight=None, d...   \n",
       "0           XGBClassifier  XGBClassifier(base_score=0.5, booster=None, co...   \n",
       "0          LGBMClassifier  LGBMClassifier(boosting_type='gbdt', class_wei...   \n",
       "0  DecisionTreeClassifier  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "0  RandomForestClassifier  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "0    KNeighborsClassifier  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "\n",
       "   cv_train  train_accuray_score  test_accuray_score  \n",
       "0  0.704804             0.807163            0.705443  \n",
       "0  0.682794             0.697844            0.677492  \n",
       "0  0.658321             0.663866            0.643092  \n",
       "0  0.612262             0.625870            0.604051  \n",
       "0  0.567193             0.567193            0.559466  \n",
       "0  0.556583             0.714338            0.555166  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32min 49s, sys: 54.1 s, total: 33min 43s\n",
      "Wall time: 17min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = build_models() \n",
    "df_outcome = run_models(models, X_train_transformated, y_train, X_test_transformated, y_test)\n",
    "df_outcome = df_outcome.sort_values(by=['test_accuray_score'], ascending=False)\n",
    "display.display(df_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.93 ms, sys: 0 ns, total: 3.93 ms\n",
      "Wall time: 2.86 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_model.model']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.externals import joblib\n",
    "best_model = df_outcome.at[0, 'model_object'][0]\n",
    "joblib.dump(best_model,  'best_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 49s, sys: 54 s, total: 7min 43s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test = pd.read_csv('gs://dataproc-6ca41800-27b4-47d5-abee-55c011dfa389-asia-southeast1/data/kaggle/test.csv')\n",
    "df_test_X = pipeline.transform(df_test['Comment'])\n",
    "best_model = joblib.load('best_model.model')\n",
    "df_test['Outcome'] = best_model.predict(df_test_X)\n",
    "test_result = df_test[['Id', 'Outcome']]\n",
    "test_result.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload best_model.model to data/kaggle/best_model.model\n",
      "Upload submission.csv to data/kaggle/submission.csv\n",
      "CPU times: user 32.4 ms, sys: 4.73 ms, total: 37.1 ms\n",
      "Wall time: 305 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket('dataproc-6ca41800-27b4-47d5-abee-55c011dfa389-asia-southeast1')\n",
    "\n",
    "def upload_files(bucket, files):\n",
    "    for file in files:\n",
    "        butcketFile = 'data/kaggle/' + file\n",
    "        blob = bucket.blob(butcketFile)\n",
    "        blob.upload_from_filename(file)\n",
    "        print(\"Upload {0} to {1}\".format(file, butcketFile))\n",
    "    \n",
    "upload_files(bucket, ['best_model.model','submission.csv'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
